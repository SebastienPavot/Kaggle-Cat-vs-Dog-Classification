{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "hide_input": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9-final"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "name": "Cats vs Dogs Classification.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HnnVRvd3VkKj"
      },
      "source": [
        "# Kaggle Competition Dogs vs Cats Classification:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DwQdpvqxWN0v",
        "outputId": "bc95c8e4-0b8b-4ac4-edad-b2ba450a5832",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mfS8nRgNVkKk"
      },
      "source": [
        "_Competition link: https://www.kaggle.com/c/dogs-vs-cats/overview_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xHo4_SpXVkKk"
      },
      "source": [
        "## Libraries:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQ_LzzdaVkKl"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os, shutil\n",
        "from tensorflow.keras.models import Sequential, load_model, Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.layers import Dense, LSTM, Conv2D, Dropout, MaxPooling2D, Flatten\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array, array_to_img\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
        "from tensorflow.keras.applications import VGG16\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VnsuOR5BVkKp"
      },
      "source": [
        "## Data Importation:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w5gVQKpuVkKp"
      },
      "source": [
        "dir = '/content/drive/My Drive/Kaggle Dogs & Cats/Data'\n",
        "original_dir = '/Users/spavot/Documents/Perso/Kaggle-Cat-vs-Dog-Classification/Data/Original_Data'\n",
        "train_dir = os.path.join(dir, 'Training')\n",
        "# os.mkdir(train_dir)\n",
        "validation_dir = os.path.join(dir, 'Validation')\n",
        "# os.mkdir(validation_dir)\n",
        "test_dir = os.path.join(dir, 'Test')\n",
        "# os.mkdir(test_dir)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XqfUM9TTVkKs"
      },
      "source": [
        "#Training set directory\n",
        "train_cats_dir = os.path.join(train_dir, 'Cats')\n",
        "# os.mkdir(train_cats_dir)\n",
        "train_dogs_dir = os.path.join(train_dir, 'Dogs')\n",
        "# os.mkdir(train_dogs_dir)\n",
        "#Validation set directory\n",
        "validation_cats_dir = os.path.join(validation_dir, 'Cats')\n",
        "# os.mkdir(validation_cats_dir)\n",
        "validation_dogs_dir = os.path.join(validation_dir, 'Dogs')\n",
        "# os.mkdir(validation_dogs_dir)\n",
        "#Test set directory\n",
        "test_cats_dir = os.path.join(test_dir, 'Cats')\n",
        "# os.mkdir(test_cats_dir)\n",
        "test_dogs_dir = os.path.join(test_dir, 'Dogs')\n",
        "# os.mkdir(test_dogs_dir)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uC5IXR8_VkKv"
      },
      "source": [
        "# #Copy the image to the right directory:\n",
        "# fnames = ['cat.{}.jpg'.format(i) for i in range(8000)]\n",
        "# for fname in fnames:\n",
        "#     src = os.path.join(original_dir, fname)\n",
        "#     dst = os.path.join(train_cats_dir, fname)\n",
        "#     shutil.copyfile(src,dst)\n",
        "# #Dogs images:\n",
        "# fnames = ['dog.{}.jpg'.format(i) for i in range(8000)]\n",
        "# for fname in fnames:\n",
        "#     src = os.path.join(original_dir, fname)\n",
        "#     dst = os.path.join(train_dogs_dir, fname)\n",
        "#     shutil.copyfile(src,dst)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2x52q8tHVkKz"
      },
      "source": [
        "# #Copy the image to the validation directory:\n",
        "# #Cats images\n",
        "# fnames = ['cat.{}.jpg'.format(i) for i in range(8000,10500)]\n",
        "# for fname in fnames:\n",
        "#     src = os.path.join(original_dir, fname)\n",
        "#     dst = os.path.join(validation_cats_dir, fname)\n",
        "#     shutil.copyfile(src,dst)\n",
        "# #Dogs images:\n",
        "# fnames = ['dog.{}.jpg'.format(i) for i in range(8000,10500)]\n",
        "# for fname in fnames:\n",
        "#     src = os.path.join(original_dir, fname)\n",
        "#     dst = os.path.join(validation_dogs_dir, fname)\n",
        "#     shutil.copyfile(src,dst)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j3FIgyVIVkK2"
      },
      "source": [
        "# #Copy the image to the test directory:\n",
        "# #Cats images\n",
        "# fnames = ['cat.{}.jpg'.format(i) for i in range(10500,12500)]\n",
        "# for fname in fnames:\n",
        "#     src = os.path.join(original_dir, fname)\n",
        "#     dst = os.path.join(test_cats_dir, fname)\n",
        "#     shutil.copyfile(src,dst)\n",
        "# #Dogs images:\n",
        "# fnames = ['dog.{}.jpg'.format(i) for i in range(10500,12500)]\n",
        "# for fname in fnames:\n",
        "#     src = os.path.join(original_dir, fname)\n",
        "#     dst = os.path.join(test_dogs_dir, fname)\n",
        "#     shutil.copyfile(src,dst)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QYU8l2iOVkK5",
        "outputId": "77afc59f-67bf-4956-c744-68fb7b62cc77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "#Check if we have the correct number of pictures per set:\n",
        "print('Total training set cats:', len(os.listdir(train_cats_dir)))\n",
        "print('Total training set dogs:', len(os.listdir(train_dogs_dir)))\n",
        "print('Total validation set cats:', len(os.listdir(validation_cats_dir)))\n",
        "print('Total validation set dogs:', len(os.listdir(validation_dogs_dir)))\n",
        "print('Total test set cats:', len(os.listdir(test_cats_dir)))\n",
        "print('Total test set dogs:', len(os.listdir(test_dogs_dir)))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total training set cats: 8000\n",
            "Total training set dogs: 8000\n",
            "Total validation set cats: 2510\n",
            "Total validation set dogs: 2500\n",
            "Total test set cats: 2000\n",
            "Total test set dogs: 2000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IpWoqcYPVkK8"
      },
      "source": [
        "As expected, we have 8000 training samples of each class, 2000 for validation set and finally 2500 for the testing set to confirm the results and avoid overfitting on the validation set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-cBIOPBVkK9"
      },
      "source": [
        "## Data preprocessing:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJab_5MsVkK9",
        "outputId": "02b66dc5-4b51-49de-f601-cb900654127f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "#Because we have a lot of data, we won't load them and instead use a generator:\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "val_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "\n",
        "batch_size = 50\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    color_mode = 'rgb',\n",
        "    target_size = (150, 150),\n",
        "    batch_size = batch_size,\n",
        "    class_mode = 'binary'\n",
        ")\n",
        "validation_generator = val_datagen.flow_from_directory(\n",
        "    validation_dir,\n",
        "    color_mode = 'rgb',\n",
        "    target_size = (150, 150),\n",
        "    batch_size = batch_size,\n",
        "    class_mode = 'binary'\n",
        ")"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 16000 images belonging to 2 classes.\n",
            "Found 5010 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z8IRZlIhVkLA",
        "outputId": "0abe13d0-87e3-4284-cb30-8388d3b106b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "#Sanity check:\n",
        "for data, labels in train_generator:\n",
        "    print(data.shape)\n",
        "    print(labels.shape)\n",
        "    break\n",
        "for data, labels in validation_generator:\n",
        "    print(data.shape)\n",
        "    print(labels.shape)\n",
        "    break"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50, 150, 150, 3)\n",
            "(50,)\n",
            "(50, 150, 150, 3)\n",
            "(50,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e9RCBiY4VkLC"
      },
      "source": [
        "Seems to be as we wanted, we have our generators ready!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y0qx7rYhVkLD"
      },
      "source": [
        "## Modeling using Keras and CNN layers:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-aMyG590VkLD"
      },
      "source": [
        "First we will create callbacks to save the model and stop it when it start overfitting. Note that we use accuracy as the metric as our classes are equally distributed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5dcRi_pnVkLE"
      },
      "source": [
        "Model_Name = ''\n",
        "callback = [EarlyStopping(monitor='val_accuracy', patience=3), ModelCheckpoint(filepath = '/Users/spavot/Documents/Perso/Kaggle-Cat-vs-Dog-Classification/Models/'+ Model_Name, monitor = 'val_accuracy', save_best_only = True)]"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vUz_ajF6VkLG"
      },
      "source": [
        "## Own build model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4enhTvg2VkLH",
        "outputId": "758d772e-2a95-4c84-bd9e-08dbcf42da17",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        }
      },
      "source": [
        "#Assign the variable to a name for saving the best model\n",
        "Model_Name = 'Own_1st_Model_CNN.h5'\n",
        "#Build the model\n",
        "own_model = Sequential()\n",
        "own_model.add(Conv2D(32,(3,3), activation = 'relu', input_shape = (150,150,3)))\n",
        "own_model.add(MaxPooling2D((2,2)))\n",
        "own_model.add(Conv2D(32, (3,3), activation = 'relu'))\n",
        "own_model.add(MaxPooling2D((2,2)))\n",
        "own_model.add(Conv2D(32, (3,3), activation = 'relu'))\n",
        "own_model.add(MaxPooling2D((2,2)))\n",
        "own_model.add(Flatten())\n",
        "own_model.add(Dropout(0.5))\n",
        "own_model.add(Dense(512, activation = 'relu'))\n",
        "own_model.add(Dense(1, activation = 'sigmoid'))\n",
        "#Compile the model\n",
        "own_model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
        "#Print the summary of the model\n",
        "own_model.summary()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_3 (Conv2D)            (None, 148, 148, 32)      896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 74, 74, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 72, 72, 32)        9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 36, 36, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 34, 34, 32)        9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 17, 17, 32)        0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 9248)              0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 9248)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 512)               4735488   \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 513       \n",
            "=================================================================\n",
            "Total params: 4,755,393\n",
            "Trainable params: 4,755,393\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fWJ68zgDVkLJ",
        "outputId": "3a0c8f06-e6ae-4fe9-e416-3e827bae9099",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        }
      },
      "source": [
        "#Initiate a callback to stop when the model start overfitting, we do not use checkpoint save as it can crash with Google Colab\n",
        "callback = EarlyStopping(monitor='val_accuracy', patience=3)\n",
        "#Fit the model using train_generator for training and validation_generator for testing\n",
        "history = own_model.fit(\n",
        "    train_generator,\n",
        "    epochs = 30,\n",
        "    validation_data = validation_generator,\n",
        "    steps_per_epoch = train_generator.samples//train_generator.batch_size,\n",
        "    validation_steps = validation_generator.samples//validation_generator.batch_size,\n",
        "    callbacks = [callback],\n",
        "    verbose = 1)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-29-f95e4d328ca9>:11: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use Model.fit, which supports generators.\n",
            "Epoch 1/30\n",
            "  1/320 [..............................] - ETA: 0s - loss: 0.7121 - accuracy: 0.4000"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-f95e4d328ca9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mvalidation_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidation_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     verbose = 1)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m               \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m               instructions)\n\u001b[0;32m--> 324\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m     return tf_decorator.make_decorator(\n\u001b[1;32m    326\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'deprecated'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1827\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1828\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1829\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1831\u001b[0m   @deprecation.deprecated(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vkZQOOw6VkLM"
      },
      "source": [
        "#Save the model\n",
        "own_model.save('/content/drive/My Drive/Kaggle Dogs & Cats/Models/OwnV3.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJ0UqBlnVkLO"
      },
      "source": [
        "#Plot the loss evolution for training / validation sets\n",
        "epochs = np.arange(1, len(history.history['loss'])+1)\n",
        "fig = go.Figure()\n",
        "fig.add_trace(go.Scatter(name = 'Training set', x = epochs, y = history.history['loss']))\n",
        "fig.add_trace(go.Scatter(name = 'Validation set', x = epochs, y = history.history['val_loss']))\n",
        "fig.update_layout(\n",
        "    title=\"Training & Validation loss evolution\",\n",
        "    xaxis_title=\"Epochs\",\n",
        "    yaxis_title=\"Loss\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DkEtbjUGVkLR"
      },
      "source": [
        "#Plot the accuracy evolution for training / validation sets\n",
        "epochs = np.arange(1, len(history.history['loss'])+1)\n",
        "fig = go.Figure()\n",
        "fig.add_trace(go.Scatter(name = 'Training set', x = epochs, y = history.history['accuracy']))\n",
        "fig.add_trace(go.Scatter(name = 'Validation set', x = epochs, y = history.history['val_accuracy']))\n",
        "fig.update_layout(\n",
        "    title=\"Training & Validation accuracy evolution\",\n",
        "    xaxis_title=\"Epochs\",\n",
        "    yaxis_title=\"Loss\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B5IlDk1zVkLT"
      },
      "source": [
        "Our model seems to overfit very fast, we will try to use data augmentation. This technique help to regularize the model and improve performance by changing a little bit the data so the model won't see twice the same image when training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_Uni4zpVkLT"
      },
      "source": [
        "#Create an augmented generator\n",
        "Aug_datagen = ImageDataGenerator(\n",
        "    rotation_range = 40,\n",
        "    width_shift_range = 0.2,\n",
        "    height_shift_range = 0.2,\n",
        "    shear_range = 0.2,\n",
        "    zoom_range = 0.2,\n",
        "    horizontal_flip = True,\n",
        "    fill_mode = 'nearest'\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q1KBdXSTVkLW"
      },
      "source": [
        "#Get the path of a randomly selected image\n",
        "fnames = [os.path.join(train_cats_dir, fname) for fname in os.listdir(train_cats_dir)]\n",
        "img = load_img(fnames[7], target_size = (150,150))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wG7GWeLSVkLY"
      },
      "source": [
        "#Transform image to array and reshape it to (1,150,150,3)\n",
        "cat_img = img_to_array(img)\n",
        "cat_img = cat_img.reshape((1,) + cat_img.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qqTJgyH0VkLa"
      },
      "source": [
        "#Plot only four version of the image:\n",
        "x = 0\n",
        "f, axarr = plt.subplots(1,4, figsize=(20,30))\n",
        "for i in Aug_datagen.flow(cat_img, batch_size = 1):\n",
        "    axarr[x].imshow(array_to_img(i[0]))\n",
        "    x += 1\n",
        "    if x % 4 == 0:\n",
        "        break\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L830bpG7VkLd"
      },
      "source": [
        "Now that we seen what augmented generator does, let's apply it to our model to improve the accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cOvKWhY0VkLd"
      },
      "source": [
        "#Initiate new generators:\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale = 1./255,\n",
        "    rotation_range = 40,\n",
        "    width_shift_range = 0.2,\n",
        "    height_shift_range = 0.2,\n",
        "    shear_range = 0.2,\n",
        "    zoom_range = 0.2,\n",
        "    horizontal_flip = True,\n",
        "    fill_mode = 'nearest'\n",
        ")\n",
        "\n",
        "#Initiate test generator with only rescale parameter (for test we don't want to modify the data)\n",
        "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "\n",
        "#Training generator\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size = (150,150),\n",
        "    batch_size = 50,\n",
        "    class_mode = 'binary'\n",
        ")\n",
        "#Validation generator\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "    validation_dir,\n",
        "    target_size = (150,150),\n",
        "    batch_size = 50,\n",
        "    class_mode = 'binary'\n",
        ")\n",
        "#Test generator\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size = (150,150),\n",
        "    batch_size = 50,\n",
        "    class_mode = 'binary'\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uc7gzrwhWZ6S"
      },
      "source": [
        "#Assign the variable to a name for saving the best model\n",
        "Model_Name = 'Own_2nd_Model_CNN.h5'\n",
        "#Build the model\n",
        "own_model_aug = Sequential()\n",
        "own_model_aug.add(Conv2D(32,(3,3), activation = 'relu', input_shape = (150,150,3)))\n",
        "own_model_aug.add(MaxPooling2D((2,2)))\n",
        "own_model_aug.add(Conv2D(32, (3,3), activation = 'relu'))\n",
        "own_model_aug.add(MaxPooling2D((2,2)))\n",
        "own_model_aug.add(Conv2D(32, (3,3), activation = 'relu'))\n",
        "own_model_aug.add(MaxPooling2D((2,2)))\n",
        "own_model_aug.add(Flatten())\n",
        "own_model_aug.add(Dropout(0.5))\n",
        "own_model_aug.add(Dense(512, activation = 'relu'))\n",
        "own_model_aug.add(Dense(1, activation = 'sigmoid'))\n",
        "#Compile the model\n",
        "own_model_aug.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
        "#Print the summary of the model\n",
        "own_model_aug.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xK1Msj3kVkLf"
      },
      "source": [
        "#Initiate a callback to stop when the model start overfitting, we do not use checkpoint save as it can crash with Google Colab\n",
        "callback = EarlyStopping(monitor='val_accuracy', patience=3)\n",
        "#Fit the model using train_generator for training and validation_generator for testing\n",
        "history_augmented = own_model_aug.fit(\n",
        "    train_generator,\n",
        "    epochs = 30,\n",
        "    validation_data = validation_generator,\n",
        "    steps_per_epoch = train_generator.samples//train_generator.batch_size,\n",
        "    validation_steps = validation_generator.samples//validation_generator.batch_size,\n",
        "    callbacks = [callback],\n",
        "    verbose = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mF7W_lv6VkLh"
      },
      "source": [
        "#Save the model\n",
        "own_model.save('/content/drive/My Drive/Kaggle Dogs & Cats/Models/Own_Aug_V3.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IvXSixDiVkLl"
      },
      "source": [
        "#Plot the loss evolution for training / validation sets\n",
        "epochs = np.arange(1, len(history_augmented.history['loss'])+1)\n",
        "fig = go.Figure()\n",
        "fig.add_trace(go.Scatter(name = 'Training set', x = epochs, y = history_augmented.history['loss']))\n",
        "fig.add_trace(go.Scatter(name = 'Validation set', x = epochs, y = history_augmented.history['val_loss']))\n",
        "fig.update_layout(\n",
        "    title=\"Training & Validation loss evolution\",\n",
        "    xaxis_title=\"Epochs\",\n",
        "    yaxis_title=\"Loss\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_3Ck2iABVkLn"
      },
      "source": [
        "#Plot the accuracy evolution for training / validation sets\n",
        "epochs = np.arange(1, len(history_augmented.history['loss'])+1)\n",
        "fig = go.Figure()\n",
        "fig.add_trace(go.Scatter(name = 'Training set', x = epochs, y = history_augmented.history['accuracy']))\n",
        "fig.add_trace(go.Scatter(name = 'Validation set', x = epochs, y = history_augmented.history['val_accuracy']))\n",
        "fig.update_layout(\n",
        "    title=\"Training & Validation accuracy evolution\",\n",
        "    xaxis_title=\"Epochs\",\n",
        "    yaxis_title=\"Loss\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8oW6gRZvVkLq"
      },
      "source": [
        "We improved the model performance but we can do better. Unfortunately, stuck with not big computational power and a low sample of training images, we might not achieve way better for this classification. To improve our performance, we will use a pretrain model on a big dataset of millions of images and use this one for our competition. What we will do is freeze the first layers that contain the global information and let this new model only train the last layers. As it has been trained to detect images and animals, the global pattern can stay frozen where the deeper layers needs to be updated for our specific usecase."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cB9GdehPVkLr"
      },
      "source": [
        "## Pretrained Model:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1qAXAk39VkLr"
      },
      "source": [
        "Note that we will still use augmented data for our pretrained model as it increases performance and regularize the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dXkPfJ1iVkLr"
      },
      "source": [
        "### Freeze all the imported model:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PHDG04fpVkLs"
      },
      "source": [
        "For the first part, we will completely freeze the model imported and just let the two dense layers we will add being able to be trained."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9--yonIZVkLs"
      },
      "source": [
        "#Download the pretrain model\n",
        "pretrain_base = VGG16(weights = 'imagenet',\n",
        "                       include_top = False,\n",
        "                       input_shape = (150,150,3))\n",
        "#Print the summary of this model\n",
        "pretrain_base.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "79D02CEeVkLu"
      },
      "source": [
        "It is a way bigger network with this time 14 millions of parameters, training all of them would take a long time and not be usefull as we want to use the weights already pretrain for our problem. Note that we didn't took the include_top as it contains a dense layer of 1000 possible outputs where we only want 2 possible outputs so let's finish the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQBM3zCvVkLv"
      },
      "source": [
        "#Freeze the pretrain part of the model\n",
        "pretrain_base.trainable = False\n",
        "#Add flatten, densely connected and output layers:\n",
        "pretrain_model = Sequential()\n",
        "pretrain_model.add(pretrain_base)\n",
        "pretrain_model.add(Flatten())\n",
        "pretrain_model.add(Dense(512, activation = 'relu'))\n",
        "pretrain_model.add(Dense(1, activation = 'sigmoid'))\n",
        "\n",
        "#Compile the model\n",
        "pretrain_model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
        "\n",
        "#Print the summary of the new model\n",
        "pretrain_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yd9pkt39VkLx"
      },
      "source": [
        "We now have 18 millions of parameters, thankfully, we froze the pretrain model. We can see that only 4 millions of parameters are now trainable."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wtvlnw3uVkLx"
      },
      "source": [
        "#Initiate a callback to stop when the model start overfitting, we do not use checkpoint save as it can crash with Google Colab\n",
        "callback = EarlyStopping(monitor='val_accuracy', patience=3)\n",
        "#Fit the model using train_generator for training and validation_generator for testing\n",
        "history_pretrain = pretrain_model.fit(\n",
        "    train_generator,\n",
        "    epochs = 30,\n",
        "    validation_data = validation_generator,\n",
        "    steps_per_epoch = train_generator.samples//train_generator.batch_size,\n",
        "    validation_steps = validation_generator.samples//validation_generator.batch_size,\n",
        "    callbacks = [callback]\n",
        "    verbose = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SOOkBKi0VkLz"
      },
      "source": [
        "#Save the model\n",
        "pretrain_model.save('/content/drive/My Drive/Kaggle Dogs & Cats/Models/pre_trainable.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wyEeJRkbVkL1"
      },
      "source": [
        "#Plot the loss evolution for training / validation sets\n",
        "epochs = np.arange(1, len(history_pretrain.history['loss'])+1)\n",
        "fig = go.Figure()\n",
        "fig.add_trace(go.Scatter(name = 'Training set', x = epochs, y = history_pretrain.history['loss']))\n",
        "fig.add_trace(go.Scatter(name = 'Validation set', x = epochs, y = history_pretrain.history['val_loss']))\n",
        "fig.update_layout(\n",
        "    title=\"Training & Validation loss evolution\",\n",
        "    xaxis_title=\"Epochs\",\n",
        "    yaxis_title=\"Loss\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dDf7KlNoVkL3"
      },
      "source": [
        "#Plot the accuracy evolution for training / validation sets\n",
        "epochs = np.arange(1, len(history_augmented.history['loss'])+1)\n",
        "fig = go.Figure()\n",
        "fig.add_trace(go.Scatter(name = 'Training set', x = epochs, y = history_pretrain.history['accuracy']))\n",
        "fig.add_trace(go.Scatter(name = 'Validation set', x = epochs, y = history_pretrain.history['val_accuracy']))\n",
        "fig.update_layout(\n",
        "    title=\"Training & Validation accuracy evolution\",\n",
        "    xaxis_title=\"Epochs\",\n",
        "    yaxis_title=\"Loss\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0P8toh0qVkL5"
      },
      "source": [
        "### Unfreeze the last 3 layers of the pretrain model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Qy9Rl_0VkL5"
      },
      "source": [
        "#Download the pretrain model\n",
        "pretrain_base = VGG16(weights = 'imagenet',\n",
        "                       include_top = False,\n",
        "                       input_shape = (150,150,3))\n",
        "#Print the summary of this model\n",
        "pretrain_base.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nu0mJFGdVkL7"
      },
      "source": [
        "We want to unfreeze the layers from block5_conv1:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yh58ELV6VkL8"
      },
      "source": [
        "#Make the last 3 layers trainable\n",
        "pretrain_base.trainable = True\n",
        "set_trainable = False\n",
        "#For loop to unfreeze the last 3 layers\n",
        "for layer in pretrain_base.layers:\n",
        "    #When we reach the first layer, set_trainable becomes true\n",
        "    if layer.name == 'block5_conv1':\n",
        "        set_trainable = True\n",
        "    #So from this point, when set_trainable is true, the layer is changed to be able to be trained\n",
        "    if set_trainable:\n",
        "        layer.trainable = True\n",
        "    #Before we reach the first layer mentionned above, the layers are switch to be unfreeze\n",
        "    else:\n",
        "        layer.trainable = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "91eRWAfPVkL-"
      },
      "source": [
        "#Check the summary again\n",
        "pretrain_base.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jA6TVQVrVkMA"
      },
      "source": [
        "We now see that we have 7 millions parameters trainable which corresponds to the last 3 layers, let's build our model again:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QaJ3k1RYVkMB"
      },
      "source": [
        "#Add flatten, densely connected and output layers:\n",
        "pretrain_trainable_model = Sequential()\n",
        "pretrain_trainable_model.add(pretrain_base)\n",
        "pretrain_trainable_model.add(Flatten())\n",
        "pretrain_trainable_model.add(Dense(512, activation = 'relu'))\n",
        "pretrain_trainable_model.add(Dense(1, activation = 'sigmoid'))\n",
        "\n",
        "#Initiate an optimizer\n",
        "opti = Adam(lr = 0.00001)\n",
        "#Compile the model this time using a very low learning rate to don't change totally the last layers weights\n",
        "pretrain_model.compile(loss = 'binary_crossentropy', optimizer = opti, metrics = ['accuracy'])\n",
        "\n",
        "#Print the summary of the new model\n",
        "pretrain_trainable_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vbyiYx4XVkMC"
      },
      "source": [
        "We now have 11 millions trainable parameters compared to 4 millions previously with the total frozen model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4frXxHd-VkMD"
      },
      "source": [
        "#Initiate a callback to stop when the model start overfitting, we do not use checkpoint save as it can crash with Google Colab\n",
        "callback = EarlyStopping(monitor='val_accuracy', patience=3)\n",
        "#Fit the model using train_generator for training and validation_generator for testing\n",
        "history_pretrain_trainable = pretrain_trainable_model.fit(\n",
        "    train_generator,\n",
        "    epochs = 3,\n",
        "    validation_data = validation_generator,\n",
        "    steps_per_epoch = train_generator.samples//train_generator.batch_size,\n",
        "    validation_steps = validation_generator.samples//validation_generator.batch_size,\n",
        "    callbacks = [callback],\n",
        "    verbose = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RVSDrooSVkME"
      },
      "source": [
        "#Save the model\n",
        "pretrain_trainable_model.save('/content/drive/My Drive/Kaggle Dogs & Cats/Models/pre_trainable.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FsSZx15dVkMG"
      },
      "source": [
        "#Plot the loss evolution for training / validation sets\n",
        "epochs = np.arange(1, len(history_pretrain_trainable.history['loss'])+1)\n",
        "fig = go.Figure()\n",
        "fig.add_trace(go.Scatter(name = 'Training set', x = epochs, y = history_pretrain_trainable.history['loss']))\n",
        "fig.add_trace(go.Scatter(name = 'Validation set', x = epochs, y = history_pretrain_trainable.history['val_loss']))\n",
        "fig.update_layout(\n",
        "    title=\"Training & Validation loss evolution\",\n",
        "    xaxis_title=\"Epochs\",\n",
        "    yaxis_title=\"Loss\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R0YDmHK8VkMJ"
      },
      "source": [
        "#Plot the accuracy evolution for training / validation sets\n",
        "epochs = np.arange(1, len(history_pretrain_trainable.history['loss'])+1)\n",
        "fig = go.Figure()\n",
        "fig.add_trace(go.Scatter(name = 'Training set', x = epochs, y = history_pretrain_trainable.history['accuracy']))\n",
        "fig.add_trace(go.Scatter(name = 'Validation set', x = epochs, y = history_pretrain_trainable.history['val_accuracy']))\n",
        "fig.update_layout(\n",
        "    title=\"Training & Validation accuracy evolution\",\n",
        "    xaxis_title=\"Epochs\",\n",
        "    yaxis_title=\"Loss\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N9AhEXM9VkML"
      },
      "source": [
        "## Visualize what the models learned:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LRvymOdtVkML"
      },
      "source": [
        "Convolutionnal model are models that are not black box. We can run the inverse process of training the model to get the a visual of what each convolutionnal layer learned and so understand what it represent within an image."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dRAiCjl8VkML"
      },
      "source": [
        "To do so, we will first load the model we trained previously in Google Colab Cloud as our computer was not enough powerfull to handle them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gjgEUXEbVkMM"
      },
      "source": [
        "#Load first model:\n",
        "own_model = load_model('/Users/spavot/Documents/Perso/Kaggle-Cat-vs-Dog-Classification/Models/own_model.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hUvFmvPVVkMO"
      },
      "source": [
        "We first laod an image from the validation set (so the model didn't trained on it):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HRYKZLi8VkMP"
      },
      "source": [
        "img_path = os.path.join(validation_dir, 'Cats/cat.8501.jpg')\n",
        "img = load_img(img_path, target_size = (150,150))\n",
        "img_tensor = img_to_array(img)\n",
        "img_tensor = np.expand_dims(img_tensor, axis = 0)\n",
        "img_tensor /= 255.\n",
        "\n",
        "print(img_tensor.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZOINH7fYVkMR"
      },
      "source": [
        "#Print the image\n",
        "plt.imshow(img_tensor[0])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6vCm_OrzVkMT"
      },
      "source": [
        "Let's now visualize every channel in every intermediate layers:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rdoQTTgPVkMT"
      },
      "source": [
        "#First display a summary of the model:\n",
        "own_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kbv-H8NoVkMV"
      },
      "source": [
        "#Initiate an array of layers name\n",
        "layers_name = []\n",
        "for layer in own_model.layers[:6]:\n",
        "    layers_name.append(layer.name)\n",
        "print(layers_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vzRn7D-FVkMW"
      },
      "source": [
        "layers_outputs = [layer.output for layer in own_model.layers[:6]]\n",
        "activation_model = Model(inputs = own_model.input, outputs = layers_outputs)\n",
        "activations = activation_model.predict(img_tensor)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nUHrSj1QVkMY"
      },
      "source": [
        "We only have the convolutionnal layers as expected, let's create a function now to visualiza their activations for every channels:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hLzTkEjPVkMZ"
      },
      "source": [
        "def visualize_activation(layers_name, activations, images_per_row):\n",
        "    for layer_name, layer_activation in zip(layers_name, activations):\n",
        "        n_features = layer_activation.shape[-1]\n",
        "\n",
        "        size = layer_activation.shape[1]\n",
        "\n",
        "        n_cols = n_features // images_per_row\n",
        "        display_grid = np.zeros((size*n_cols, images_per_row * size))\n",
        "\n",
        "        for col in range(n_cols):\n",
        "            for row in range(images_per_row):\n",
        "                channel_image = layer_activation[0,:,:, col * images_per_row + row]\n",
        "                channel_image -= channel_image.mean()\n",
        "                channel_image /= channel_image.std()\n",
        "                channel_image *= 64\n",
        "                channel_image +=128\n",
        "                channel_image = np.clip(channel_image, 0, 255).astype('uint8')\n",
        "                display_grid[col * size : (col + 1) * size, row * size : (row + 1)* size] = channel_image\n",
        "        scale = 1. / size\n",
        "        plt.figure(figsize = (scale * display_grid.shape[1], scale * display_grid.shape[0]))\n",
        "        plt.title(layer_name)\n",
        "        plt.grid(False)\n",
        "        plt.imshow(display_grid, aspect = 'auto', cmap = 'viridis')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cuknkjoqVkMa"
      },
      "source": [
        "visualize_activation(layers_name, activations, 16)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VJKaYxVzVkMc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}