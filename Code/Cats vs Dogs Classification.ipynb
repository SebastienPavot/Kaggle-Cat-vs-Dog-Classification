{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.7.9 64-bit ('KerasTensorflow': conda)",
   "display_name": "Python 3.7.9 64-bit ('KerasTensorflow': conda)",
   "metadata": {
    "interpreter": {
     "hash": "1585c9fa3d24124dbd82c1edc671be0cf6b8e99d135a296389cea8ebc9a636dc"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Kaggle Competition Dogs vs Cats Classification:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "_Competition link: https://www.kaggle.com/c/dogs-vs-cats/overview_"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Libraries:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, shutil\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Conv2D, Dropout, MaxPooling2D, Flatten\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping"
   ]
  },
  {
   "source": [
    "## Data Importation:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = '/Users/spavot/Documents/Perso/Kaggle-Cat-vs-Dog-Classification/Data'\n",
    "original_dir = '/Users/spavot/Documents/Perso/Kaggle-Cat-vs-Dog-Classification/Data/Original_Data'\n",
    "train_dir = os.path.join(dir, 'Training')\n",
    "# os.mkdir(train_dir)\n",
    "validation_dir = os.path.join(dir, 'Validation')\n",
    "# os.mkdir(validation_dir)\n",
    "test_dir = os.path.join(dir, 'Test')\n",
    "# os.mkdir(test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training set directory\n",
    "train_cats_dir = os.path.join(train_dir, 'Cats')\n",
    "# os.mkdir(train_cats_dir)\n",
    "train_dogs_dir = os.path.join(train_dir, 'Dogs')\n",
    "# os.mkdir(train_dogs_dir)\n",
    "#Validation set directory\n",
    "validation_cats_dir = os.path.join(validation_dir, 'Cats')\n",
    "# os.mkdir(validation_cats_dir)\n",
    "validation_dogs_dir = os.path.join(validation_dir, 'Dogs')\n",
    "# os.mkdir(validation_dogs_dir)\n",
    "#Test set directory\n",
    "test_cats_dir = os.path.join(test_dir, 'Cats')\n",
    "#os.mkdir(test_cats_dir)\n",
    "test_dogs_dir = os.path.join(test_dir, 'Dogs')\n",
    "#os.mkdir(test_dogs_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Copy the image to the right directory:\n",
    "# fnames = ['cat.{}.jpg'.format(i) for i in range(8000)]\n",
    "# for fname in fnames:\n",
    "#     src = os.path.join(original_dir, fname)\n",
    "#     dst = os.path.join(train_cats_dir, fname)\n",
    "#     shutil.copyfile(src,dst)\n",
    "# #Dogs images:\n",
    "# fnames = ['dog.{}.jpg'.format(i) for i in range(8000)]\n",
    "# for fname in fnames:\n",
    "#     src = os.path.join(original_dir, fname)\n",
    "#     dst = os.path.join(train_dogs_dir, fname)\n",
    "#     shutil.copyfile(src,dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Copy the image to the validation directory:\n",
    "# #Cats images\n",
    "# fnames = ['cat.{}.jpg'.format(i) for i in range(8000,10000)]\n",
    "# for fname in fnames:\n",
    "#     src = os.path.join(original_dir, fname)\n",
    "#     dst = os.path.join(validation_cats_dir, fname)\n",
    "#     shutil.copyfile(src,dst)\n",
    "# #Dogs images:\n",
    "# fnames = ['dog.{}.jpg'.format(i) for i in range(8000,10000)]\n",
    "# for fname in fnames:\n",
    "#     src = os.path.join(original_dir, fname)\n",
    "#     dst = os.path.join(validation_dogs_dir, fname)\n",
    "#     shutil.copyfile(src,dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Copy the image to the test directory:\n",
    "# #Cats images\n",
    "# fnames = ['cat.{}.jpg'.format(i) for i in range(10000,12500)]\n",
    "# for fname in fnames:\n",
    "#     src = os.path.join(original_dir, fname)\n",
    "#     dst = os.path.join(test_cats_dir, fname)\n",
    "#     shutil.copyfile(src,dst)\n",
    "# #Dogs images:\n",
    "# fnames = ['dog.{}.jpg'.format(i) for i in range(10000,12500)]\n",
    "# for fname in fnames:\n",
    "#     src = os.path.join(original_dir, fname)\n",
    "#     dst = os.path.join(test_dogs_dir, fname)\n",
    "#     shutil.copyfile(src,dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Total training set cats: 8000\nTotal training set dogs: 8000\nTotal validation set cats: 2000\nTotal validation set dogs: 2000\nTotal test set cats: 2500\nTotal test set dogs: 2500\n"
     ]
    }
   ],
   "source": [
    "#Check if we have the correct number of pictures per set:\n",
    "print('Total training set cats:', len(os.listdir(train_cats_dir)))\n",
    "print('Total training set dogs:', len(os.listdir(train_dogs_dir)))\n",
    "print('Total validation set cats:', len(os.listdir(validation_cats_dir)))\n",
    "print('Total validation set dogs:', len(os.listdir(validation_dogs_dir)))\n",
    "print('Total test set cats:', len(os.listdir(test_cats_dir)))\n",
    "print('Total test set dogs:', len(os.listdir(test_dogs_dir)))"
   ]
  },
  {
   "source": [
    "As expected, we have 8000 training samples of each class, 2000 for validation set and finally 2500 for the testing set to confirm the results and avoid overfitting on the validation set."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Data preprocessing:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found 16000 images belonging to 2 classes.\nFound 4000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "#Because we have a lot of data, we won't load them and instead use a generator:\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "val_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "train_size = (len(os.listdir(train_cats_dir)) + len(os.listdir(train_dogs_dir)))\n",
    "validation_size = (len(os.listdir(validation_cats_dir)) + len(os.listdir(validation_dogs_dir)))\n",
    "batch_size = 40\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size = (200,200),\n",
    "    batch_size = batch_size,\n",
    "    class_mode = 'binary'\n",
    ")\n",
    "validation_generator = val_datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    target_size = (200,200),\n",
    "    batch_size = batch_size,\n",
    "    class_mode = 'binary'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Data batch shape (40, 200, 200, 3)\nLabel batch shape (40,)\n"
     ]
    }
   ],
   "source": [
    "#Sanity check:\n",
    "for data, labels in train_generator:\n",
    "    print('Data batch shape', data.shape)\n",
    "    print('Label batch shape', labels.shape)\n",
    "    break"
   ]
  },
  {
   "source": [
    "Seems to be as we wanted, we have our generators ready!"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Modeling using Keras and CNN layers:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "First we will create callbacks to save the model and stop it when it start overfitting. Note that we use accuracy as the metric as our classes are equally distributed."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model_Name = ''\n",
    "callback = [EarlyStopping(monitor='val_accuracy', patience=3), ModelCheckpoint(filepath = '/Users/spavot/Documents/Perso/Kaggle-Cat-vs-Dog-Classification/Models'+ Model_Name, monitor = 'val_accuracy', save_best_only = True)]"
   ]
  },
  {
   "source": [
    "## Own build model:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d_3 (Conv2D)            (None, 198, 198, 32)      896       \n_________________________________________________________________\nmax_pooling2d_3 (MaxPooling2 (None, 99, 99, 32)        0         \n_________________________________________________________________\nconv2d_4 (Conv2D)            (None, 97, 97, 32)        9248      \n_________________________________________________________________\nmax_pooling2d_4 (MaxPooling2 (None, 48, 48, 32)        0         \n_________________________________________________________________\nconv2d_5 (Conv2D)            (None, 46, 46, 32)        9248      \n_________________________________________________________________\nmax_pooling2d_5 (MaxPooling2 (None, 23, 23, 32)        0         \n_________________________________________________________________\nflatten_1 (Flatten)          (None, 16928)             0         \n_________________________________________________________________\ndense_2 (Dense)              (None, 128)               2166912   \n_________________________________________________________________\ndense_3 (Dense)              (None, 1)                 129       \n=================================================================\nTotal params: 2,186,433\nTrainable params: 2,186,433\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Assign the variable to a name for saving the best model\n",
    "Model_Name = 'Own_1st_Model_CNN.h5'\n",
    "#Build the model\n",
    "own_model = Sequential()\n",
    "own_model.add(Conv2D(32,(3,3), activation = 'relu', input_shape = (200,200,3)))\n",
    "own_model.add(MaxPooling2D((2,2)))\n",
    "own_model.add(Conv2D(32, (3,3), activation = 'relu'))\n",
    "own_model.add(MaxPooling2D((2,2)))\n",
    "own_model.add(Conv2D(32, (3,3), activation = 'relu'))\n",
    "own_model.add(MaxPooling2D((2,2)))\n",
    "own_model.add(Flatten())\n",
    "own_model.add(Dense(128, activation = 'relu'))\n",
    "own_model.add(Dense(1, activation = 'sigmoid'))\n",
    "#Compile the model\n",
    "own_model.compile(loss = 'binary_crossentropy', opti = 'adam', metrics = ['accuracy'])\n",
    "#Print the summary of the model\n",
    "own_model.summary()"
   ]
  },
  {
   "source": [
    "Let's fit our first model:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Need a cloud GPU to run it"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = own_model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch = train_size//batch_size,\n",
    "    epochs = 15,\n",
    "    validation_data = validation_generator,\n",
    "    validation_steps = validation_size//batch_size,\n",
    "    verbose = True\n",
    ")"
   ]
  }
 ]
}